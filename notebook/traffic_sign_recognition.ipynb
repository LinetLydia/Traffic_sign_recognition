{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e173bd7-f218-42c9-886a-7014a69ae2f0",
   "metadata": {},
   "source": [
    "**Imports & config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "721fa11c-6c88-44e0-9d88-fc748e49da6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\miniconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from opencv-python) (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53ce29ae-e76a-4ae5-a4b8-08b806d362c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random, shutil, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "DATA_DIR = \"C:/Users/hp/projects/traffic-sign-recognition/data/GTSRB/Train\"\n",
    "IMG_SIZE = (48, 48)  # common choice for GTSRB\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03668f38-82cc-4837-99b6-532c33960263",
   "metadata": {},
   "source": [
    "**Load file paths + labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa271342-918b-417b-8e39-5d4224724bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34889, 40)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert os.path.isdir(DATA_DIR), f\"Folder not found: {DATA_DIR}\"\n",
    "\n",
    "def list_images_and_labels(root):\n",
    "    # Each class is a folder named 00000, 00001, ...\n",
    "    class_dirs = sorted([d for d in glob.glob(os.path.join(root, \"*\")) if os.path.isdir(d)])\n",
    "    paths, labels = [], []\n",
    "    for class_dir in class_dirs:\n",
    "        label = int(os.path.basename(class_dir))\n",
    "        for img_path in glob.glob(os.path.join(class_dir, \"*.ppm\")) + glob.glob(os.path.join(class_dir, \"*.png\")) + glob.glob(os.path.join(class_dir, \"*.jpg\")):\n",
    "            paths.append(img_path)\n",
    "            labels.append(label)\n",
    "    return paths, labels\n",
    "\n",
    "all_paths, all_labels = list_images_and_labels(DATA_DIR)\n",
    "n_classes = len(set(all_labels))\n",
    "len(all_paths), n_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87103d55-9ffe-4531-9b19-1fbba4886745",
   "metadata": {},
   "source": [
    "**Train/val split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503afb06-2e21-40d5-b590-5c3ab8e1c402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27911, 6978)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    all_paths, all_labels, test_size=0.2, stratify=all_labels, random_state=SEED\n",
    ")\n",
    "len(train_paths), len(val_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcd2a8f-2d4f-407a-8896-7a051659854f",
   "metadata": {},
   "source": [
    "**TF data pipeline (fast, memory-friendly)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff99a488-c915-4d46-a8e4-694e160398e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(path, label, augment=False):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    if augment:\n",
    "        img = tf.image.random_flip_left_right(img)               # mild; some signs are symmetric, be careful\n",
    "        img = tf.image.random_brightness(img, max_delta=0.1)\n",
    "        img = tf.image.random_contrast(img, 0.9, 1.1)\n",
    "    img = (img - 0.5) * 2.0  # scale to [-1,1]\n",
    "    return img, tf.cast(label, tf.int32)\n",
    "\n",
    "def make_dataset(paths, labels, augment=False, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=min(len(paths), 10000), seed=SEED)\n",
    "    ds = ds.map(lambda p,l: preprocess_image(p,l,augment=augment), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_dataset(train_paths, train_labels, augment=True, shuffle=True)\n",
    "val_ds   = make_dataset(val_paths, val_labels, augment=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56c5fa-6af4-466a-8e3f-b53cc00ae02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
